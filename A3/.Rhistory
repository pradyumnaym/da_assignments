cor_mat = cor(ames_quantitative)
#different methods of the correlation plot
methods = c("circle", "square", "ellipse", "number", "shade", "color", "pie")
#colors = colorRampPalette(c("red", "white", "blue"))(20)
plt = function(){
corrplot(cor_mat, #matrix of correlation
method = methods[5], #shade
type = "lower", #lower triangular matrix only
diag=FALSE, #exclude the diagonal
order="hclust", #heirarchical clustering
col = brewer.pal(n=8, name="RdBu"), #Use RColorBrewer to get a palette of blue and red gradient
tl.col="black", #color of text
tl.srt = 45, #tilt by 45 degrees
addCoef.col = "black", #Add correlation coefficients in each box
number.cex = 0.7,
tl.cex = 0.8        )
title(main = 'Correlogram of AMES quantitative variables', line = -2)
}
plt()
print(
paste(
"The summary statistics for GrLivArea are:",
summary(ames_quantitative$GrLivArea)
)
)
print(
paste(
"The summary statistics for SqFootage are:",
summary(ames_quantitative$SqFootage)
)
)
summary(ames_quantitative$GrLivArea)
summary(ames_quantitative$SqFootage)
#corrgram(ames_quantitative, order=NULL, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt,main="Quantitative variables of AMES")
print("The summary statistics for SqFootage are:")
train = "AmesHousingPrices/train.csv"
test = "AmesHousingPrices/test.csv"
ames_train = read.csv(paste(path,train,sep=""))
ames_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(ames_train)
ames_quantitative = ames_train[,c(3,10,19,20,22)]
drop = c("X","Id")
ames_quantitative = ames_quantitative[,!(names(ames_quantitative) %in% drop)]
#Ref: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
#cor() reutrns a matrix of correlation values
cor_mat = cor(ames_quantitative)
#different methods of the correlation plot
methods = c("circle", "square", "ellipse", "number", "shade", "color", "pie")
#colors = colorRampPalette(c("red", "white", "blue"))(20)
plt = function(){
corrplot(cor_mat, #matrix of correlation
method = methods[5], #shade
type = "lower", #lower triangular matrix only
diag=FALSE, #exclude the diagonal
order="hclust", #heirarchical clustering
col = brewer.pal(n=8, name="RdBu"), #Use RColorBrewer to get a palette of blue and red gradient
tl.col="black", #color of text
tl.srt = 45, #tilt by 45 degrees
addCoef.col = "black", #Add correlation coefficients in each box
number.cex = 0.7,
tl.cex = 0.8        )
title(main = 'Correlogram of AMES quantitative variables', line = -2)
}
plt()
print("The summary statistics for GrLivArea are:")
summary(ames_quantitative$GrLivArea)
print("The summary statistics for SqFootage are:")
summary(ames_quantitative$SqFootage)
#corrgram(ames_quantitative, order=NULL, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt,main="Quantitative variables of AMES")
hist(ames_quantitative$GrLivArea)
hist(ames_quantitative$SqFootage)
train = "AmesHousingPrices/train.csv"
test = "AmesHousingPrices/test.csv"
ames_train = read.csv(paste(path,train,sep=""))
ames_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(ames_train)
ames_quantitative = ames_train[,c(3,10,19,20,22)]
drop = c("X","Id")
ames_quantitative = ames_quantitative[,!(names(ames_quantitative) %in% drop)]
#Ref: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
#cor() reutrns a matrix of correlation values
cor_mat = cor(ames_quantitative)
#different methods of the correlation plot
methods = c("circle", "square", "ellipse", "number", "shade", "color", "pie")
#colors = colorRampPalette(c("red", "white", "blue"))(20)
plt = function(){
corrplot(cor_mat, #matrix of correlation
method = methods[5], #shade
type = "lower", #lower triangular matrix only
diag=FALSE, #exclude the diagonal
order="hclust", #heirarchical clustering
col = brewer.pal(n=8, name="RdBu"), #Use RColorBrewer to get a palette of blue and red gradient
tl.col="black", #color of text
tl.srt = 45, #tilt by 45 degrees
addCoef.col = "black", #Add correlation coefficients in each box
number.cex = 0.7,
tl.cex = 0.8        )
title(main = 'Correlogram of AMES quantitative variables', line = -2)
}
plt()
print("The summary statistics for GrLivArea are:")
summary(ames_quantitative$GrLivArea)
print("The summary statistics for SqFootage are:")
summary(ames_quantitative$SqFootage)
hist(ames_quantitative$GrLivArea)
hist(ames_quantitative$SqFootage)
#corrgram(ames_quantitative, order=NULL, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt,main="Quantitative variables of AMES")
qualityvalues = split(ames_train, OverallQuality)
qualityvalues = split(ames_train, ames_train$OverallQuality)
qualityvalues = split(ames_train, ames_train$OverallQual)
boxplot(qualityvalues)
qualityvalues = split(ames_train, ames_train$OverallQual)
boxplot(qualityvalues)
qualityvalues = split(ames_train, ames_train$OverallQual)
boxplot(unlist(qualityvalues))
qualityvalues
qualityvalues = split(ames_train[,"SalePrice"], ames_train$OverallQual)
boxplot(qualityvalues)
qualityvalues = split(ames_train[,"SalePrice"], ames_train$OverallQual)
boxplot(qualityvalues,
main = "Boxplot of the sales price for each level of OverallQuality",
xlab = "OverallQual",
ylab = "SalesPrice")
model <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model)
p <- predict(model,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p , ames_test$SalePrice)
)
)
plot(model)
hist(ames_train$SalePrice)
ames_test[,"SalePrice"] <- log(ames_test[,"SalePrice"])
ames_train[,"SalePrice"] <- log(ames_train[,"SalePrice"])
hist(ames_test$SalePrice)
model <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model)
p <- predict(model,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p , ames_test$SalePrice)
)
)
plot(model, which  = c(1,2,3))
#install.packages('corrplot')
#install.packages('RColorBrewer')
#install.packages('glmnet')
#install.packages('caret')
library(RColorBrewer)
library(corrplot)
library(glmnet)
library(caret)
# path to the Dataset
path='D:/DA/A3/'
train = "AmesHousingPrices/train.csv"
test = "AmesHousingPrices/test.csv"
ames_train = read.csv(paste(path,train,sep=""))
ames_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(ames_train)
ames_quantitative = ames_train[,c(3,10,19,20,22)]
drop = c("X","Id")
ames_quantitative = ames_quantitative[,!(names(ames_quantitative) %in% drop)]
#Ref: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
#cor() reutrns a matrix of correlation values
cor_mat = cor(ames_quantitative)
#different methods of the correlation plot
methods = c("circle", "square", "ellipse", "number", "shade", "color", "pie")
#colors = colorRampPalette(c("red", "white", "blue"))(20)
plt = function(){
corrplot(cor_mat, #matrix of correlation
method = methods[5], #shade
type = "lower", #lower triangular matrix only
diag=FALSE, #exclude the diagonal
order="hclust", #heirarchical clustering
col = brewer.pal(n=8, name="RdBu"), #Use RColorBrewer to get a palette of blue and red gradient
tl.col="black", #color of text
tl.srt = 45, #tilt by 45 degrees
addCoef.col = "black", #Add correlation coefficients in each box
number.cex = 0.7,
tl.cex = 0.8        )
title(main = 'Correlogram of AMES quantitative variables', line = -2)
}
plt()
print("The summary statistics for GrLivArea are:")
summary(ames_quantitative$GrLivArea)
print("The summary statistics for SqFootage are:")
summary(ames_quantitative$SqFootage)
hist(ames_quantitative$GrLivArea)
hist(ames_quantitative$SqFootage)
#corrgram(ames_quantitative, order=NULL, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt,main="Quantitative variables of AMES")
qualityvalues = split(ames_train[,"SalePrice"], ames_train$OverallQual)
boxplot(qualityvalues,
main = "Boxplot of the sales price for each level of OverallQuality",
xlab = "OverallQual",
ylab = "SalesPrice")
model <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model)
p <- predict(model,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p , ames_test$SalePrice)
)
)
plot(model, which  = c(1,2,3))
hist(ames_train$SalePrice)
ames_test[,"SalePrice"] <- log(ames_test[,"SalePrice"])
ames_train[,"SalePrice"] <- log(ames_train[,"SalePrice"])
hist(ames_test$SalePrice)
model2 <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model2)
p <- predict(model2,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p , ames_test$SalePrice)
)
)
plot(model2)
print(
paste(
"The R2 value of the first model is:",
summary(model)$r.squared
)
)
print(
paste(
"The R2 value of the second model is:",
summary(model2)$r.squared
)
)
train = "ShenzhenHousingPrices/train.csv"
test = "ShenzhenHousingPrices/test.csv"
shen_train = read.csv(paste(path,train,sep=""))
shen_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(shen_train)
drop = c("SalePrice")
X_train = data.matrix(shen_train[,!(names(shen_train) %in% drop)])
y_train = subset(shen_train,select = drop)
y_train = data.matrix(log(y_train))
X_test = data.matrix(shen_test[,!(names(shen_test) %in% drop)])
y_test = subset(shen_test,select = drop)
y_test = data.matrix(log(y_test))
grid = 10^seq(10, -2, length = 100)
ridge_mod = glmnet(X_train, y_train, alpha = 0, lambda = grid)
cv_fit <- cv.glmnet(X_train, y_train, alpha = 0, lambda = grid)
plot(cv_fit)
best_lambda = cv_fit$lambda.min
print(paste("Best lambda: ",best_lambda,sep=""))
p = predict(ridge_mod,s = best_lambda, newx = X_test)
print(paste("RMSE: ",RMSE(p , y_test),sep=""))
print(paste("R2: ",R2(p , y_test),sep=""))
lasso_mod = glmnet(X_train, y_train, alpha = 1, lambda = grid)
cv_fit <- cv.glmnet(X_train, y_train, alpha = 1, lambda = grid)
plot(cv_fit)
best_lambda = cv_fit$lambda.min
print(best_lambda)
print(paste("Best lambda: ",best_lambda,sep=""))
p = predict(lasso_mod,s = best_lambda, newx = X_test)
print(paste("RMSE: ",RMSE(p , y_test),sep=""))
print(paste("R2: ",R2(p , y_test),sep=""))
p2
p1 <- predict(model, ames_test)
p2<- predict(model, ames_test)
p2
p1 <- predict(model, ames_test)
p2<- predict(model2, ames_test)
p2
p1 <- predict(model, ames_test)
p2<- predict(model2, ames_test)
p2<- exp(1) ^ p2
mae(p1, ames_test$SalePrice)
p1 <- predict(model, ames_test)
p2<- predict(model2, ames_test)
p2<- exp(1) ^ p2
MAE(p1, ames_test$SalePrice)
MAE(p2, ames_test$SalePrice)
p1 <- predict(model, ames_test)
p2<- predict(model2, ames_test)
p2<- exp(1) ^ p2
print(
paste(
"The MAE of the first Model is:",
MAE(p1, ames_test$SalePrice)
)
)
print(
paste(
"The MAE of the first Model is:",
MAE(p1, ames_test$SalePrice)
)
)
p1 <- predict(model, ames_test)
p2<- predict(model2, ames_test)
p2<- exp(1) ^ p2
print(
paste(
"The MAE of the first Model is:",
MAE(p1, ames_test$SalePrice)
)
)
print(
paste(
"The MAE of the first Model is:",
MAE(p2, ames_test$SalePrice)
)
)
#install.packages('corrplot')
#install.packages('RColorBrewer')
#install.packages('glmnet')
#install.packages('caret')
library(RColorBrewer)
library(corrplot)
library(glmnet)
library(caret)
# path to the Dataset
path='D:/DA/A3/'
train = "AmesHousingPrices/train.csv"
test = "AmesHousingPrices/test.csv"
ames_train = read.csv(paste(path,train,sep=""))
ames_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(ames_train)
ames_quantitative = ames_train[,c(3,10,19,20,22)]
drop = c("X","Id")
ames_quantitative = ames_quantitative[,!(names(ames_quantitative) %in% drop)]
#Ref: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
#cor() reutrns a matrix of correlation values
cor_mat = cor(ames_quantitative)
#different methods of the correlation plot
methods = c("circle", "square", "ellipse", "number", "shade", "color", "pie")
#colors = colorRampPalette(c("red", "white", "blue"))(20)
plt = function(){
corrplot(cor_mat, #matrix of correlation
method = methods[5], #shade
type = "lower", #lower triangular matrix only
diag=FALSE, #exclude the diagonal
order="hclust", #heirarchical clustering
col = brewer.pal(n=8, name="RdBu"), #Use RColorBrewer to get a palette of blue and red gradient
tl.col="black", #color of text
tl.srt = 45, #tilt by 45 degrees
addCoef.col = "black", #Add correlation coefficients in each box
number.cex = 0.7,
tl.cex = 0.8        )
title(main = 'Correlogram of AMES quantitative variables', line = -2)
}
plt()
print("The summary statistics for GrLivArea are:")
summary(ames_quantitative$GrLivArea)
print("The summary statistics for SqFootage are:")
summary(ames_quantitative$SqFootage)
hist(ames_quantitative$GrLivArea)
hist(ames_quantitative$SqFootage)
#corrgram(ames_quantitative, order=NULL, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt,main="Quantitative variables of AMES")
qualityvalues = split(ames_train[,"SalePrice"], ames_train$OverallQual)
boxplot(qualityvalues,
main = "Boxplot of the sales price for each level of OverallQuality",
xlab = "OverallQual",
ylab = "SalesPrice")
model <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model)
p1 <- predict(model,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p , ames_test$SalePrice)
)
)
model <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model)
p1 <- predict(model,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p1 , ames_test$SalePrice)
)
)
plot(model, which  = c(1,2,3))
#install.packages('corrplot')
#install.packages('RColorBrewer')
#install.packages('glmnet')
#install.packages('caret')
library(RColorBrewer)
library(corrplot)
library(glmnet)
library(caret)
# path to the Dataset
path='D:/DA/A3/'
train = "AmesHousingPrices/train.csv"
test = "AmesHousingPrices/test.csv"
ames_train = read.csv(paste(path,train,sep=""))
ames_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(ames_train)
ames_quantitative = ames_train[,c(3,10,19,20,22)]
drop = c("X","Id")
ames_quantitative = ames_quantitative[,!(names(ames_quantitative) %in% drop)]
#Ref: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
#cor() reutrns a matrix of correlation values
cor_mat = cor(ames_quantitative)
#different methods of the correlation plot
methods = c("circle", "square", "ellipse", "number", "shade", "color", "pie")
#colors = colorRampPalette(c("red", "white", "blue"))(20)
plt = function(){
corrplot(cor_mat, #matrix of correlation
method = methods[5], #shade
type = "lower", #lower triangular matrix only
diag=FALSE, #exclude the diagonal
order="hclust", #heirarchical clustering
col = brewer.pal(n=8, name="RdBu"), #Use RColorBrewer to get a palette of blue and red gradient
tl.col="black", #color of text
tl.srt = 45, #tilt by 45 degrees
addCoef.col = "black", #Add correlation coefficients in each box
number.cex = 0.7,
tl.cex = 0.8        )
title(main = 'Correlogram of AMES quantitative variables', line = -2)
}
plt()
print("The summary statistics for GrLivArea are:")
summary(ames_quantitative$GrLivArea)
print("The summary statistics for SqFootage are:")
summary(ames_quantitative$SqFootage)
hist(ames_quantitative$GrLivArea)
hist(ames_quantitative$SqFootage)
#corrgram(ames_quantitative, order=NULL, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt,main="Quantitative variables of AMES")
qualityvalues = split(ames_train[,"SalePrice"], ames_train$OverallQual)
boxplot(qualityvalues,
main = "Boxplot of the sales price for each level of OverallQuality",
xlab = "OverallQual",
ylab = "SalesPrice")
model <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model)
p1 <- predict(model,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p1 , ames_test$SalePrice)
)
)
plot(model, which  = c(1,2,3))
hist(ames_train$SalePrice)
ames_test[,"SalePrice"] <- log(ames_test[,"SalePrice"])
ames_train[,"SalePrice"] <- log(ames_train[,"SalePrice"])
hist(ames_test$SalePrice)
model2 <- lm(SalePrice ~ . -X -Id, ames_train)
#summary(model2)
p2 <- predict(model2,ames_test)
print(
paste(
"The RMS error of the first model on the test set is:",
RMSE(p2 , ames_test$SalePrice)
)
)
plot(model2)
print(
paste(
"The R2 value of the first model is:",
summary(model)$r.squared
)
)
print(
paste(
"The R2 value of the second model is:",
summary(model2)$r.squared
)
)
p1 <- predict(model, ames_test)
p2<- predict(model2, ames_test)
p2<- exp(1) ^ p2
print(
paste(
"The MAE of the first Model is:",
MAE(p1, ames_test$SalePrice)
)
)
print(
paste(
"The MAE of the first Model is:",
MAE(p2, ames_test$SalePrice)
)
)
train = "ShenzhenHousingPrices/train.csv"
test = "ShenzhenHousingPrices/test.csv"
shen_train = read.csv(paste(path,train,sep=""))
shen_test = read.csv(paste(path,test,sep=""))
#dummy = na.omit(shen_train)
drop = c("SalePrice")
X_train = data.matrix(shen_train[,!(names(shen_train) %in% drop)])
y_train = subset(shen_train,select = drop)
y_train = data.matrix(log(y_train))
X_test = data.matrix(shen_test[,!(names(shen_test) %in% drop)])
y_test = subset(shen_test,select = drop)
y_test = data.matrix(log(y_test))
grid = 10^seq(10, -2, length = 100)
ridge_mod = glmnet(X_train, y_train, alpha = 0, lambda = grid)
cv_fit <- cv.glmnet(X_train, y_train, alpha = 0, lambda = grid)
plot(cv_fit)
best_lambda = cv_fit$lambda.min
print(paste("Best lambda: ",best_lambda,sep=""))
p = predict(ridge_mod,s = best_lambda, newx = X_test)
print(paste("RMSE: ",RMSE(p , y_test),sep=""))
print(paste("R2: ",R2(p , y_test),sep=""))
lasso_mod = glmnet(X_train, y_train, alpha = 1, lambda = grid)
cv_fit <- cv.glmnet(X_train, y_train, alpha = 1, lambda = grid)
plot(cv_fit)
best_lambda = cv_fit$lambda.min
print(best_lambda)
print(paste("Best lambda: ",best_lambda,sep=""))
p = predict(lasso_mod,s = best_lambda, newx = X_test)
print(paste("RMSE: ",RMSE(p , y_test),sep=""))
print(paste("R2: ",R2(p , y_test),sep=""))
